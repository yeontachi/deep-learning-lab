## 실험 목적
이번 실험의 목적은 CNN 모델에 Dropout을 적용함으로써 과적합(Overfitting)을 방지하고 일반화 성능을 향상시킬 수 있는지 확인하는 것이다. 기존 모델은 Dropout 없이 훈련되었고, 이후 Dropout(0.5확률)을 적용한 모델로 동일한 학습 조건에서 성능을 비교하였다.

## 실험 조건 요약

| 항목                | Dropout 미적용               | Dropout 적용 (p=0.5)             |
| ----------------- | ------------------------- | ------------------------------ |
| Conv 레이어 구조       | Conv2D(3x3) - Conv2D(3x3) | 동일                             |
| Fully Connected 층 | FC(128) → FC(10)          | **FC(128 → Dropout → FC(10))** |
| Epoch 수           | 30                        | 30                             |
| Batch size        | 32                        | 32                             |
| Optimizer         | Adam                      | Adam                           |
| Dataset           | MNIST (Train/Val/Test 분할) | 동일                             |


## EPOCH별 Train/Validatioin 성능

| Epoch | Train Loss | Train Accuracy | Val Loss | Val Accuracy |
|-------|------------|----------------|----------|--------------|
| 1     | 0.2857     | 91.11%         | 0.0788   | 97.58%       |
| 2     | 0.1069     | 96.90%         | 0.0525   | 98.36%       |
| 3     | 0.0775     | 97.67%         | 0.0443   | 98.66%       |
| 4     | 0.0643     | 98.05%         | 0.0446   | 98.63%       |
| 5     | 0.0504     | 98.49%         | 0.0410   | 98.73%       |
| 6     | 0.0448     | 98.65%         | 0.0405   | 98.73%       |
| 7     | 0.0402     | 98.80%         | 0.0407   | 98.83%       |
| 8     | 0.0354     | 98.93%         | 0.0401   | 98.92%       |
| 9     | 0.0294     | 99.08%         | 0.0360   | 99.12%       |
| 10    | 0.0272     | 99.14%         | 0.0400   | 99.05%       |
| 11    | 0.0249     | 99.19%         | 0.0439   | 98.91%       |
| 12    | 0.0234     | 99.23%         | 0.0500   | 98.95%       |
| 13    | 0.0222     | 99.30%         | 0.0394   | 99.03%       |
| 14    | 0.0191     | 99.35%         | 0.0349   | 99.15%       |
| 15    | 0.0176     | 99.43%         | 0.0412   | 99.09%       |
| 16    | 0.0167     | 99.43%         | 0.0527   | 99.02%       |
| 17    | 0.0162     | 99.45%         | 0.0457   | 99.08%       |
| 18    | 0.0157     | 99.49%         | 0.0426   | 99.11%       |
| 19    | 0.0154     | 99.50%         | 0.0482   | 99.11%       |
| 20    | 0.0129     | 99.54%         | 0.0453   | 99.08%       |
| 21    | 0.0147     | 99.51%         | 0.0441   | 99.12%       |
| 22    | 0.0118     | 99.60%         | 0.0448   | 99.16%       |
| 23    | 0.0117     | 99.62%         | 0.0449   | 99.08%       |
| 24    | 0.0122     | 99.58%         | 0.0464   | 99.14%       |
| 25    | 0.0110     | 99.61%         | 0.0596   | 99.11%       |
| 26    | 0.0096     | 99.67%         | 0.0592   | 99.03%       |
| 27    | 0.0117     | 99.64%         | 0.0477   | 99.17%       |
| 28    | 0.0105     | 99.69%         | 0.0671   | 99.01%       |
| 29    | 0.0109     | 99.66%         | 0.0603   | 99.06%       |
| 30    | 0.0110     | 99.66%         | 0.0534   | 99.08%       |

## 평균 성능 비교( 30 epoch 기준 )

| 성능 항목             | Dropout 미적용 | Dropout 적용 (p=0.5) |
| ----------------- | ----------- | ------------------ |
| 평균 Train Loss     | **0.0192**  | 0.0354             |
| 평균 Train Accuracy | **99.59%**  | 98.90%             |
| 평균 Val Loss       | 0.0652      | **0.0477**         |
| 평균 Val Accuracy   | 98.85%      | **98.94%**         |
| 최종 Test Loss      | 0.0735      | **0.0480**         |
| 최종 Test Accuracy  | 98.85%      | **99.10%**         |


## 성능 변화 분석
1. **Train Loss 및 Accuracy**
 - Dropout을 적용하지 않은 경우, 평균 Train Loss는 낮고 Accuracy는 매우 높다ㅏ.(과적합의 징후)
 - Dropout 적용 후에는 학습 정확도는 다소 낮아졌지만, 이는 모델이 더 일반화된 표현을 학습했음을 의미한다.

2. **Validation / Test 성능**
 - Val/Test Accuracy는 Dropout 적용 모델이 더 높게 유지된다.
 - Dropout 적용 전에는 Epoch이 진행될수록 Val Loss가 증가( -> 과적합), 반면 Dropout 모델은 Val Loss가 더 안정적으로 유지됨.

3. **과적합 완화 효과**
 - Dropout은 훈련 중 일부 뉴런을 무작위로 제거함으로써 특정 뉴런에 의존하는 경향을 방지하고, 보다 다양한 특징 조합을 학습하도록 유도한다.
 - 이로 인해 Train Accuracy는 낮아지지만, Validation/Test Accuracy는 더 높거나 안정적인 경향을 보인다.

## 결론
 - Dropout을 적용함으로써 일부 성능 손해(Train Accuracy 감소)를 감수하더라도, **일반화 성능(Test Accuracy 향상)**을 얻을 수 있었다.
 - 특히, CNN처럼 파라미터 수가 많고, 적은 데이터셋(MNIST 등)에 쉽게 과적합되는 구조에서는 Dropout이 매우 유효한 정규화 기법임을 확인할 수 있었다.
 - 향후에는 Dropout 위치 조정, 확률 값(p) 튜닝, BatchNorm과의 조합 등을 통해 더 종교한 정규화 전략을 탐색할 수 있다.