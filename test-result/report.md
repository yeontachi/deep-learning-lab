# MNIST CNN 기본 실험 보고서

## 실험 개요
 - **모델 구조** : 2층 CNN(Conv -> ReLU -> MaxPool) + 2층 완전 연결층(FC)
 - **데이터셋** : MNIST(28x28 크기의 흑백 손글씨 숫자 이미지, 총 10개 클래스)
 - **프레임워크** : PyTorch
 - **학습 Epoch 수** : 10
 - **Optimizer** : Adam(Learning rate = 0.001)
 - **활성화 함수** : ReLU
 - **정규화 기법** : 없음
 - **평가 지표** : CrossEntropyLoss, Accuracy, Confusion Matrix

## 최종 결과
 - **최종 테스트 정확도(Accuracy)** : 99.03%
 - **최종 테스트 손실(Loss)** : 0.0373%

 모델은 전체적으로 우수한 성능을 보였으나, **혼동 행렬(Confusion Matrix)**를 분석해보면, 일부 숫자 간에 구체적인 혼동 경향이 존재함

 ![Alt text](/test-result/mnist-cnn-base-test1.png)

 ![Alt text](/test-result/mnist-cnn-base-test2.png)

### 테스트 정확도 변동에 대한 해석
 이번 실험에서는 동일한 CNN 구조로 두 번의 학습을 진행한 결과, 테스트 정확도는 각각 98.85%, **99.03%**로 0.1%~0.2% 수준의 오차 범위 내에서 변동이 발생했다.
 이는 딥러닝 모델 학습에서 매우 일반적이고 자연스러운 현상으로, 아래와 같은 요소들에 의해 발생할 수 있다.

 - **가중치 초기화의 무작위성** : 신경망의 학습은 가중치 초기값에 따라 다른 수렴 경로를 따르게 되며, 특히 Epoch 수가 적거나 네트워크 구조가 단순한 경우 이 영향이 더 크게 작용할 수 있다.
 - **데이터 로딩의 무작위성** : 학습 데이터는 DataLoader에서 매 epoch마다 무작위 배치로 로딩되며(shuffle=True), 이로 인해 **optimizer가 처리하는 데이터 순서가 달라지고,** 결과적으로 **gradient** 경로가 바뀔 수 있다.
 - **GPU 연산의 비결정성** : CUDA 기반의 GPU 연산은 병렬성과 최적화 때문에 일부 연산 결과에서 미세한 차이가 발생할 수 있으며, 이러한 수치 오차는 전체 정확도에 소폭 영향을 미친다.
 - **Dropout 사용 시(본 실험에서는 미사용)** : Dropout은 학습 시 뉴런을 무작위로 끄는 방식이므로, 같은 네트워크 구조라도 학습 시점에 따라 모델이 조금씩 다르게 작동한다.

 이와 같은 정확도 차이는 딥러닝 실험에서 통계적으로 무시 가능한 수준의 오차이며, 모델이 잘못 작동하거나 과적합되었다는 의미는 아니다. 따라서 이번 결과에서의 0.1%~0.2% 수준 정확도 차이는 정상적인 변동 범위로 해석할 수 있다. 만약 실험의 재현성과 절대 비교가 중요한 경우, 정확도 고정도 가능하다.(하지만 실제 연구 및 개발 환경에서는 일부 랜덤성을 허용한 채 평균 성능을 평가하는 것이 더 실용적인 접근이다.)


### 클래스별 혼동 분석

| 실제 숫자 (True) | 혼동된 숫자 (Predicted) | 혼동 원인                      |
| ------------ | ------------------ | -------------------------- |
| `0`          | `6`, `7`, `8`, `9` | 둥근 외형의 유사성                 |
| `1`          | `3`                | 세로 막대 형태와 곡선 혼동            |
| `2`          | `7`                | 위쪽 구조 유사                   |
| `3`          | `5`                | 곡선 중심의 구조 유사               |
| `4`          | `9`                | 오른쪽 윗부분과 꺾임 구조 유사          |
| `5`          | `3`                | 하단 곡선 유사성                  |
| `6`          | `0`                | 닫힌 원 형태 유사                 |
| `7`          | `2`                | 상단 구조 유사                   |
| `8`          | `0`, `3`           | 닫힌 고리형 구조 유사               |
| `9`          | `4`                | 상단+하단 구조가 4와 비슷하게 필기될 수 있음 |

### 개선 방향
정규화(regularization) 기법 없이도 높은 정확도를 달성했지만, 일부 숫자 쌍에서는 여전히 시각적 유사성으로 인한 오분류가 존재

**개선 실험 제안**

| 실험 내용                   | 기대 효과          | 예시 브랜치명                     |
| ----------------------- | -------------- | --------------------------- |
| Dropout 추가              | 과적합 방지, 일반화 향상 | `mnist-cnn-dropout`         |
| BatchNorm 추가            | 학습 안정화, 성능 향상  | `mnist-cnn-batchnorm`       |
| Conv 레이어 3층 확장          | 더 정교한 특징 추출    | `mnist-cnn-3conv`           |
| 데이터 증강 (회전, 노이즈 등)      | 다양한 필기체 대응     | `mnist-cnn-augmentation`    |
| 활성화 함수 변경 (LeakyReLU 등) | 죽은 ReLU 방지     | `mnist-cnn-activation-test` |
| 필터 크기 변경 (5×5 등)        | 넓은 시야 확보       | `mnist-cnn-kernel5`         |



## 결론
 이번 실험은 **Pytorch 기반 CNN의 기본 구조만으로도 MNIST 데이터에 대해 매우 높은 정확도(99% 이상)**을 달성할 수 있음을 확인함.
  하지만 Confusion Matrix 분석을 통해 여전히 시각적으로 유사한 숫자 간의 오분류가 발생하고 있음을 발견하였고, 이를 바탕으로 다음 실험 설계를 위한 구체적 개선 방향도 도출할 수 있었음.