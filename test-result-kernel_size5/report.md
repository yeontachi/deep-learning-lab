# MNIST CNN Kernel_Size 변경 실험 보고서

## 실험 개요
 - **모델 구조** : 2층 CNN(Conv -> ReLU -> MaxPool) + 2층 완전 연결층(FC)
 - **데이터셋** : MNIST(28x28 크기의 흑백 손글씨 숫자 이미지, 총 10개 클래스)
 - **프레임워크** : PyTorch
 - **학습 Epoch 수** : 10
 - **Optimizer** : Adam(Learning rate = 0.001)
 - **활성화 함수** : ReLU
 - **정규화 기법** : 없음
 - **손실 함수** : CrossEntropyLoss(다중 클래스 분류에서 일반적으로 사용)
 - **평가 지표** : CrossEntropyLoss, Accuracy, Confusion Matrix
 - **변경** : kernel_size == 3 -> kernel_size == 5 (padding == 1 -> padding == 2)

 ![Alt text](/test-result-kernel_size5/images/kernel-padding-op.png)
 
## 실험 목적
 커널 크기를 3에서 5로 늘리면, 더 넓은 영역을 봐서 작은 특징들을 놓칠 수 있다고 판단하여, 정확도가 떨어지고, 손실이 커질 것이라고 예측

## 결과(train loss, acc & val loss, acc)
**Kernel_size == 3, padding == 1 결과**

| Epoch | Train Loss | Train Acc (%) | Val Loss | Val Acc (%) |
|-------|------------|----------------|----------|-------------|
| 1     | 0.1664     | 94.86          | 0.0892   | 97.16       |
| 2     | 0.0488     | 98.49          | 0.0550   | 98.35       |
| 3     | 0.0337     | 98.88          | 0.0622   | 98.08       |
| 4     | 0.0236     | 99.24          | 0.0415   | 98.87       |
| 5     | 0.0199     | 99.37          | 0.0427   | 98.79       |
| 6     | 0.0141     | 99.51          | 0.0448   | 98.82       |
| 7     | 0.0110     | 99.61          | 0.0828   | 98.04       |
| 8     | 0.0107     | 99.67          | 0.0517   | 98.89       |
| 9     | 0.0067     | 99.79          | 0.0491   | 98.83       |
| 10    | 0.0065     | 99.80          | 0.0495   | 98.99       |

**Final Test Loss:** 0.0406  
**Final Test Accuracy:** 98.80%

**Kernel_size == 5, padding == 2 결과**

| Epoch | Train Loss | Train Acc (%) | Val Loss | Val Acc (%) |
|-------|------------|----------------|----------|-------------|
| 1     | 0.1510     | 95.32          | 0.0544   | 98.37       |
| 2     | 0.0462     | 98.53          | 0.0453   | 98.74       |
| 3     | 0.0325     | 98.95          | 0.0435   | 98.59       |
| 4     | 0.0230     | 99.22          | 0.0406   | 98.79       |
| 5     | 0.0186     | 99.39          | 0.0483   | 98.67       |
| 6     | 0.0154     | 99.51          | 0.0384   | 98.82       |
| 7     | 0.0124     | 99.60          | 0.0345   | 99.11       |
| 8     | 0.0113     | 99.63          | 0.0423   | 98.85       |
| 9     | 0.0080     | 99.75          | 0.0402   | 99.08       |
| 10    | 0.0070     | 99.76          | 0.0424   | 99.06       |

**Final Test Loss:** 0.0298  
**Final Test Accuracy:** 98.80%


## Confusion matrix
**Kernel_size == 3, padding == 1 Confusion Matrix**
![Alt text](/test-result-kernel_size5/images/mnist-cnn-kernel_size3-padding1.png)

**Kernel_size == 5, padding == 2 Confusion Matrix**
![Alt text](/test-result-kernel_size5/images/Conv-kernel_size5-padding2.png)

## 결과 보고서
| 커널 크기     | Final Val Acc | Final Test Acc | Final Test Loss |
| --------- | ------------- | -------------- | --------------- |
| 3 (pad=1) | 98.99%        | 98.80%         | 0.0406          |
| 5 (pad=2) | 99.06%        | 98.80%         | **0.0298**      |

정확도는 동일하나 손실은 커널 크기 5에서 더 낮은 경향을 보인다.

즉, 커널 크기 5 모델이 더 높은 확률값으로 예측을함을 의미한다. 커널 3 모델은 정답 클래스에 대해 0.88~0.90 정도 확률을 주고 예측, 커널 5 모델은 0.95~0.99 정도로 더 강하게 확신하고 예측한다.(CrossEntropy Loss가 더 낮아짐)

**"왜 커널 사이즈 5에서 손실이 더 낮아졌는가?""**
커널 5는 커널 3보다 더 넓은 영역의 픽셀 정보를 한 번에 고려할 수 있다. 이는 곧 **Global한 패턴**을 더 잘 포착할 수 있다는 의미이다. MNIST는 상대적으로 해상도가 낮고 숫자 전체 모양을 보는 것이 중요하기 때문에, 커널 5가 한 번에 더 많은 윤곽과 구조를 포착하게 되어 손실이 낮아질 수 있다고 판단한다.

또한, 커널 3은 더 작고 로컬한 특징에 집중하는 반면, 커널 5는 더 많은 주변 정보를 묶어 한 번에 요약하므로, 각 필터가 더 명확한 의미 있는 feature를 학습할 가능성이 있다고 판단한다.

즉, MNIST는 이미지가 작고(28x28), 객체가 하나뿐이고 단순한 구조이다.(숫자 한 개) 따라서 전체 윤곽(글로벌 구조)을 보는 게 더 중요하다고 판단하였다. 따라서 커널 5로 전체 숫자 모양을 넓게 파악하고, 보다 "전체적인 구조"에 기반해 분류한 결과, 더 자신감 있는 예측을 하게되었다(손실 감소)

## 알게된 점
기존에는 손실(loss)와 정확도(Accuracy)의 관계에 대해, 손실이 크면 그에따라 정확도가 낮아진다고 생각함. 하지만 이번 실험 결과를 확인해본 결과, 손실값이 달라도, 정확도가 동일할 수 있음을 알았음.

**정확도(Accuracy)**는 "맞았냐 틀렸냐"만 확인한다. 예측 결과가 정답이면 +1, 틀리면 +0이라고 생각하면 됨. 예를 들어서, 예측값: [0.1, 0.1, 0.1, ... 0.8] -> 정답이 마지막 클래스면 "맞음" -> 정확도 증가. 예측값: [0.4, 0.1, 0.1, ... 0.3] -> 정답이 첫 번째 클래스라도 가장 큰 확률이 아니라면 "틀림" -> 정확도 감소

**손실(Loss)**는 "얼마나 확신했냐"를 확인한다. 정답 클래스에 대해 모델이 확신을 얼마나 가졌는지 평가를 한다. 예측이 맞았더라도 **확신이 약하면 손실은 클 수 있다.**
예를 들어, 정답 클래스 확률이 0.51 -> 맞긴 맞았지만 손실이 큼(CrossEntropy 기준 약 0.67). 정답 클래스 확률이 0.99 -> 손실이 매우 작음(약 0.01 이하)

정확도는 계단 함수, 손실은 연속함수라고 생각할 수 있음.

정확도는 한 번에 1%씩만 움직이지만, 손실은 정확도는 그대로여도 내부적으로 작은 변화들을 민감하게 반영함. 그래서 정확도가 같아도 손실은 다를 수 있음. 이는 모델이 같은 정답률을 내더라도 얼마나 더 자신 있게 정답을 맞히고 있는지를 손실이 알려주는 것임.

즉, 정확도가 동일해도 손실이 낮은 모델일수록 더 확신을 갖고 예측하고 있음을 의미한다.

전체적으로는, CNN에서는 **데이터의 성격**과 **네트워크 깊이, 커널 조합**이 함께 작용해서 성능을 결정하니까, 이번 실험을 통해 **커널 크기 하나만으로도 성능이 바뀔 수 있고**, 그것이 반드시 "세밀함 부족" 때문이 아니라는 걸 알게되었다.