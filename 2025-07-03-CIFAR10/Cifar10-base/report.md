# CIFAR-10 CNN Baseline Code (PyTorch)

## 모델 구조(CNN)
입력: [B, 3, 32, 32]

 └ Conv2d(3, 8, kernel=3, padding=1) → ReLU → MaxPool2d(2)
   출력: [B, 8, 16, 16]

 └ Conv2d(8, 16, kernel=3, padding=1) → ReLU → MaxPool2d(2)
   출력: [B, 16, 8, 8]

 └ Flatten → [B, 1024]

 └ Linear(1024 → 64) → ReLU

 └ Linear(64 → 32) → ReLU

 └ Linear(32 → 10)

 └ LogSoftmax(dim=1)
 
출력: [B, 10] → 클래스별 로그 확률

| 층                             | 역할                              |
| ----------------------------- | ------------------------------- |
| `Conv2d(3, 8, 3, padding=1)`  | RGB 입력을 8개의 특징맵으로 변환 (3x3 커널)   |
| `ReLU()`                      | 비선형 활성화 함수                      |
| `MaxPool2d(2)`                | 2x2 영역에서 최대값 추출, 해상도 1/2로 다운샘플링 |
| `Conv2d(8, 16, 3, padding=1)` | 8채널을 16채널로 확대                   |
| `Flatten`                     | FC층을 위해 벡터 형태로 변환               |
| `Linear(1024 → 64)`           | 전결합층 (특징 축소)                    |
| `Linear(64 → 32)`             | 전결합층 (추가 축소)                    |
| `Linear(32 → 10)`             | 클래스 수(10)로 출력 변환                |
| `LogSoftmax(dim=1)`           | 각 클래스에 대한 로그 확률 반환 (분류용 출력 포맷)  |

 - **손실 함수** : nn.CrossEntropyLoss()
    - Pytorch에서는 CrossEntropyLoss가 내부적으로 LogSoftmax + NLLLoss를 포함하므로, 출력단에서 log_softmax()를 적용한 것은 중복이지만, 큰 오류는 아님(단, 제거 권장)
 - **최적화 기법** : torch.optim.Adam
    - Learning Rate : 0.001
    - 모맨텀 기반의 Adaptive Learning Optimizer

| 항목                       | 내용                            |
| ------------------------ | ----------------------------- |
| **입력 크기**                | `[B, 3, 32, 32]`              |
| **출력 크기**                | `[B, 10]` (클래스별 로그 확률)        |
| **활성화 함수**               | `ReLU`                        |
| **출력 활성화**               | `LogSoftmax`                  |
| **손실 함수**                | `CrossEntropyLoss`            |
| **Optimizer**            | `Adam (lr=0.001)`             |
| **파라미터 수**               | 약 70K 정도 (정확한 계산은 원하시면 추가 가능) |
| **Data Augmentation 없음** | 오직 `ToTensor()`만 사용됨          |


## 성능
| Epoch | Train Loss | Train Accuracy (%) | Test Loss | Test Accuracy (%) |
|-------|------------|--------------------|-----------|--------------------|
| 1     | 1.8166     | 33.35              | 1.5755    | 43.72              |
| 2     | 1.4928     | 45.85              | 1.4445    | 48.02              |
| 3     | 1.3373     | 51.70              | 1.2646    | 55.02              |
| 4     | 1.2375     | 55.46              | 1.2256    | 56.49              |
| 5     | 1.1745     | 58.35              | 1.2163    | 56.85              |
| 6     | 1.1297     | 59.97              | 1.1497    | 59.62              |
| 7     | 1.0880     | 61.57              | 1.1039    | 60.97              |
| 8     | 1.0564     | 62.85              | 1.1060    | 60.79              |
| 9     | 1.0263     | 63.84              | 1.0989    | 61.54              |
| 10    | 1.0025     | 64.67              | 1.0834    | 62.07              |

