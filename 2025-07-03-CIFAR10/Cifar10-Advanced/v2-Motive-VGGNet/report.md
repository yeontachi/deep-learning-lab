# VGG-Inspired 모델 설계 및 성능 향상 실험
## 실험 목적
기본 CNN 모델은 비교적 단순한 Conv-Pool 구조를 따르며 **CIFAR-10**과 같은 복잡한 이미지 분류 작업에는 한계가 존재한다. 이에 따라, 대표적인 고성능 모델인 **VGGNet**의 설계 원리를 활용하여 더 깊은 구조와 작은 커널을 겹쳐 사용하는 방식으로 모델을 재구성하였다.

**VGGNet**은 3x3 커널을 여러 번 겹쳐 사용함으로써 적은 수의 파라미터로도 5x5, 7x7과 유사한 수용 영역(receptive field)을 확보할 수 있는 특징을 갖고 있다. 이러한 구조적 이점을 활용하면 **CIFAR-10**처럼 해상도가 낮지만 시각적 다양성이 높은 데이터셋에서도 효과적인 특징 추출이 가능할 것이라고 판단하였다.

## 실험 개요
VGGNet의 구조는 원래 고해상도 이미지(224x224)에 최적화되어 있으며, 다수의 Conv 층과 5개의 MaxPooling이 포함되어 있다. CIFAR-10은 32x32의 상대적으로 작은 이미지이므로, 이에 맞게 구조를 축소하였다.
전체 구조는 다음과 같이 두 개의 블록으로 구성된다.
 - **Block 1** : Conv(32)-Conv(32)-Conv(32)-MaxPool
 - **Block 2** : Conv(64)-Conv(64)-Conv(64)-
 
이후 출력은 **[B, 64, 8, 8]**이 되며, 이를 Flatten하여 [B, 4096]의 벡터로 벼환한 뒤 다음과 같은 FC Layer를 적용하였다.
- **Linear(4096 -> 128) -> ReLU**
- **Linear(128 -> 32) -> ReLU**
- **Linear(32 -> 10) -> LogSoftmax**

## 실험 결과 및 성능 비교

| 모델                                  | Train Loss | Train Acc (%) | Test Loss | Test Acc (%) |
| ----------------------------------- | ---------- | ------------- | --------- | ------------ |
| Baseline                            | 1.0025     | 64.67         | 1.0834    | 62.07        |
| VGG-Inspired                        | 0.1171     | 96.07         | 1.8573    | 68.94        |
| VGG + BatchNorm                     | 0.0436     | 98.51         | 0.9117    | 81.53        |
| VGG + BatchNorm + FC 확대             | 0.0994     | 96.53         | 0.7543    | 81.60        |
| VGG + Data Augmentation (Crop+Flip) | 0.1960     | 93.30         | 0.4279    | 87.52        |
| VGG + Crop+Flip + ColorJitter       | 0.1613     | 94.58         | 0.4943    | 86.98        |

## 분석
 - **VGG 구조의 효과** : 단순한 Conv-Pool 구조였던 BaseLine 모델에 비해, VGG 스타일의 깊은 네트워크는 Train Accuracy에서 매우 높은 성능(96%)을 기록하며 복잡한 특징 학습에 탁월한 효과를 보였다. 하지만 Test Accuracy가 68%에 그치며, Overfitting 문제까지 발생하였다.
 - **BatchNorm 적용** : 이를 해결하기 위해 각 Conv Layer 뒤에 Batch Normalization을 적용한 결과, Test Accuracy가 81% 이상으로 향상되며 일반화 성능이 크게 개선되었다. 이는 내부 공변량 변화(Internal Covariate Shift)를 줄여 학습 안정성과 성능을 높여주는 BatchNorm의 효과를 잘 보여준다.
 - **FC Layer 확대** : FC Layer의 입력/출력 크기를 128->32에서 1024->128로 확장하였을 때, 큰 폭의 성능 향상은 없었지만 Train/Test Accuracy가 모두 군형 있게 유지되며 안정적인 학습을 보여주었다. Test Loss부분에서 0.9117 -> 0.7543 으로 성능이 좋아진 것으로 판단해 확대한 FC Layer을 이후에 계속 적용하였다.
 - **데이터 증강(RandomCrop + Flip)** : 학습 데이터에 **RandomCrop(padding=4)**과 **RandomHorizonFlip**을 적용해 학습셋을 2배로 확장한 결과, Test Accuracy가 87%을 넘으며 현재까지 가장 우수한 성능을 기록하였다. 이는 모델이 다양한 시각적 변형에 대해 더 강인하게 학습되었음을 보여준다.
 - **ColorJitter 추가 실험** : 추가로 밝기(birghtness)와 채도(saturation)를 조절하는 ColorJitter를 적용한 실험에서는 오히려 Test Accuracy가 소폭 감소하였다.(87.52->86.98). 이는 지나치게 이미지의 색감을 왜곡함으로써 모델이 원래의 시각적 패턴을 일반화하지 못한 것으로 해석할 수 있다. 특히 CIFAR-10과 같이 색상 정보가 중요한 클래스가 많은 경우, 색상의 왜곡은 오히려 분류 성능 저하로 이어질 수 있다.

## 결론
본 실험을 통해 VGG 스타일의 깊은 CNN 구조가 단순한 Baseline 모델보다 훨씬 더 높은 표현력을 가지며, Batch Normalization과 데이터 증강이 일반화 성능 향상에 매우 효과적임을 확인하였다. 특히, RandomCrop + Flip 기반의 데이터 증강은 학습 데이터의 다양성을 확보하고 오버피팅을 방지하는 데 크게 기여하였다.
반면, 무분별한 색상 증강(ColorJitter)은 오히려 성능 저하를 유발할 수 있으므로, 데이터셋의 특성과 클래스 간 시각적 구분 요소를 고려한 신중한 적용이 필요하다.