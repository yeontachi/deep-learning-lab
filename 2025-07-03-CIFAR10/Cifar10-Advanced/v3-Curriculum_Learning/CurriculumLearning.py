import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.datasets import CIFAR10
from torchvision import transforms
import numpy as np
import cv2
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt

# ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# CIFAR-10 ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# Ï†ïÍ∑úÌôî Í∞í
mean = (0.4914, 0.4822, 0.4465)
std = (0.2023, 0.1994, 0.2010)

# ==================== Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ ÌÅ¥ÎûòÏä§ ==================== #

class EdgeTransform:
    def __call__(self, img):
        img = np.array(img)
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 100, 200)
        edges = Image.fromarray(edges).convert("L")
        return transforms.ToTensor()(edges).expand(3, -1, -1)  # Ï±ÑÎÑê ÎßûÏ∂îÍ∏∞

class FilledObjectTransform:
    def __call__(self, img):
        img_np = np.array(img)
        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 100, 200)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        mask = np.zeros_like(gray)
        cv2.drawContours(mask, contours, -1, 255, thickness=-1)
        mask_rgb = cv2.merge([mask]*3)
        filled = cv2.bitwise_and(img_np, mask_rgb)
        return transforms.ToTensor()(Image.fromarray(filled))

class ObjectColor_BackgroundGrayTransform:
    def __call__(self, img):
        img_np = np.array(img)
        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 100, 200)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        mask = np.zeros_like(gray)
        cv2.drawContours(mask, contours, -1, 255, thickness=-1)
        mask_3ch = cv2.merge([mask]*3)
        object_region = cv2.bitwise_and(img_np, mask_3ch)
        background_gray = cv2.GaussianBlur(gray, (7, 7), 0)
        background_rgb = cv2.merge([background_gray]*3)
        inverted_mask = cv2.bitwise_not(mask_3ch)
        background_region = cv2.bitwise_and(background_rgb, inverted_mask)
        blended = cv2.add(object_region, background_region)
        return transforms.ToTensor()(Image.fromarray(blended))

original_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

# ==================== Î™®Îç∏ Ï†ïÏùò ==================== #

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1_1 = nn.Conv2d(3, 32, 3, padding=1)
        self.bn1_1 = nn.BatchNorm2d(32)
        self.conv1_2 = nn.Conv2d(32, 32, 3, padding=1)
        self.bn1_2 = nn.BatchNorm2d(32)
        self.conv1_3 = nn.Conv2d(32, 32, 3, padding=1)
        self.bn1_3 = nn.BatchNorm2d(32)

        self.conv2_1 = nn.Conv2d(32, 64, 3, padding=1)
        self.bn2_1 = nn.BatchNorm2d(64)
        self.conv2_2 = nn.Conv2d(64, 64, 3, padding=1)
        self.bn2_2 = nn.BatchNorm2d(64)
        self.conv2_3 = nn.Conv2d(64, 64, 3, padding=1)
        self.bn2_3 = nn.BatchNorm2d(64)

        self.pool = nn.MaxPool2d(2, 2)

        self.fc1 = nn.Linear(8 * 8 * 64, 1024)
        self.bn_fc1 = nn.BatchNorm1d(1024)
        self.fc2 = nn.Linear(1024, 128)
        self.bn_fc2 = nn.BatchNorm1d(128)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        x = torch.relu(self.bn1_1(self.conv1_1(x)))
        x = torch.relu(self.bn1_2(self.conv1_2(x)))
        x = torch.relu(self.bn1_3(self.conv1_3(x)))
        x = self.pool(x)

        x = torch.relu(self.bn2_1(self.conv2_1(x)))
        x = torch.relu(self.bn2_2(self.conv2_2(x)))
        x = torch.relu(self.bn2_3(self.conv2_3(x)))
        x = self.pool(x)

        x = x.view(-1, 8 * 8 * 64)
        x = torch.relu(self.bn_fc1(self.fc1(x)))
        x = torch.relu(self.bn_fc2(self.fc2(x)))
        x = self.fc3(x)
        return torch.log_softmax(x, dim=1)

# ==================== EarlyStopping ==================== #

class EarlyStopping:
    def __init__(self, patience=5, min_delta=0.001):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = None
        self.early_stop = False

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
                print("Early stopping triggered.")

# ==================== ÌïôÏäµ & ÌèâÍ∞Ä Ìï®Ïàò ==================== #

def train(model, loader, optimizer, criterion, epoch):
    model.train()
    correct, total, running_loss = 0, 0, 0
    for i, (x, y) in enumerate(tqdm(loader, desc=f"Epoch {epoch}")):
        x, y = x.to(DEVICE), y.to(DEVICE)
        optimizer.zero_grad()
        out = model(x)
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        correct += (out.argmax(1) == y).sum().item()
        total += y.size(0)
    return running_loss / len(loader), 100 * correct / total

def evaluate(model, loader, criterion):
    model.eval()
    correct, total, test_loss = 0, 0, 0
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            out = model(x)
            test_loss += criterion(out, y).item()
            correct += (out.argmax(1) == y).sum().item()
            total += y.size(0)
    return test_loss / len(loader), 100 * correct / total

# ==================== Ïª§Î¶¨ÌÅòÎüº ÌïôÏäµ Î£®ÌîÑ ==================== #

curriculum = [
    ("Stage 1: Edge Only", EdgeTransform(), 5),
    ("Stage 2: Filled Object Only", FilledObjectTransform(), 8),
    ("Stage 3: Object Color + Background Blurred", ObjectColor_BackgroundGrayTransform(), 10),
    ("Stage 4: Original", original_transform, 15),
]

test_dataset = CIFAR10(root="./data", train=False, download=True, transform=test_transform)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

model = CNN().to(DEVICE)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

for stage_name, transform, epochs in curriculum:
    print(f"\nüß† Starting {stage_name} for {epochs} epochs")
    train_dataset = CIFAR10(root="./data", train=True, download=True, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    early_stopping = EarlyStopping(patience=3)

    for epoch in range(1, epochs + 1):
        train_loss, train_acc = train(model, train_loader, optimizer, criterion, epoch)
        test_loss, test_acc = evaluate(model, test_loader, criterion)

        print(f"[{stage_name} | Epoch {epoch}] Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%")
        early_stopping(test_loss)
        if early_stopping.early_stop:
            break
